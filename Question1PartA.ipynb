{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7446e+00, -9.3277e-01],\n",
      "        [ 5.1709e-01, -4.5354e-01],\n",
      "        [ 5.8829e-01,  7.4515e-01],\n",
      "        [ 3.1996e-02, -1.6919e-01],\n",
      "        [ 9.4559e-01,  9.1295e-01],\n",
      "        [ 1.0147e+00,  1.4593e+00],\n",
      "        [ 8.1168e-01,  8.1842e-01],\n",
      "        [ 1.2354e+00,  6.4913e-01],\n",
      "        [-4.3469e-02, -2.9049e-01],\n",
      "        [ 1.3258e+00, -3.9021e-01],\n",
      "        [ 9.1118e-01, -7.2001e-01],\n",
      "        [ 7.8370e-01, -4.6629e-01],\n",
      "        [ 2.6632e-01,  2.5126e-01],\n",
      "        [-4.2869e-01, -1.0426e+00],\n",
      "        [-2.5054e-01, -1.0574e+00],\n",
      "        [ 1.3356e+00,  1.5765e+00],\n",
      "        [ 4.1429e-02, -4.2115e-01],\n",
      "        [ 1.0873e+00,  1.2741e+00],\n",
      "        [-4.0659e-01, -1.0738e+00],\n",
      "        [ 9.5992e-02, -6.7973e-02],\n",
      "        [ 1.4426e+00, -8.3743e-01],\n",
      "        [ 1.3018e+00,  1.3478e+00],\n",
      "        [-1.1840e-01, -3.4934e-01],\n",
      "        [-2.3664e-01, -1.4208e+00],\n",
      "        [-2.4961e-01, -8.7323e-01],\n",
      "        [ 3.8406e-01, -8.2628e-01],\n",
      "        [ 3.0990e-01, -4.6959e-02],\n",
      "        [ 8.4556e-01, -6.1979e-01],\n",
      "        [ 3.6449e-01, -8.8521e-01],\n",
      "        [ 4.9885e-01,  3.7792e-01],\n",
      "        [ 1.7337e-01,  1.0722e-01],\n",
      "        [ 8.0674e-01, -5.8338e-01],\n",
      "        [ 1.4997e+00,  8.0655e-01],\n",
      "        [ 1.3412e+00,  3.3998e-01],\n",
      "        [ 5.2542e-01, -3.2114e-01],\n",
      "        [ 1.5921e-01, -6.6810e-01],\n",
      "        [ 5.8228e-01,  1.9853e-01],\n",
      "        [ 1.4449e+00, -8.2845e-01],\n",
      "        [-1.2280e-01, -3.3260e-01],\n",
      "        [-1.2958e-01, -9.0510e-01],\n",
      "        [ 5.4072e-01,  5.3759e-01],\n",
      "        [ 5.5775e-01,  3.0455e-01],\n",
      "        [ 1.3159e+00,  1.0492e+00],\n",
      "        [ 1.5680e+00, -4.7033e-01],\n",
      "        [ 5.8915e-01,  6.6844e-01],\n",
      "        [-4.1033e-02, -4.5120e-01],\n",
      "        [ 8.6396e-01, -4.5655e-01],\n",
      "        [ 1.3156e+00,  1.7439e+00],\n",
      "        [ 2.1126e-01,  1.4994e-01],\n",
      "        [ 1.2102e+00,  1.7262e-01],\n",
      "        [ 1.1593e+00, -8.1649e-01],\n",
      "        [ 5.9740e-01,  6.3528e-02],\n",
      "        [-2.2980e-01, -6.6850e-01],\n",
      "        [ 7.8683e-01,  6.1141e-01],\n",
      "        [ 5.7287e-01, -1.9347e-01],\n",
      "        [ 8.4598e-02, -1.3232e+00],\n",
      "        [ 1.0567e+00,  1.0831e+00],\n",
      "        [-1.5162e-01, -3.8378e-01],\n",
      "        [ 5.9629e-01, -6.6234e-02],\n",
      "        [ 1.5704e+00,  1.2618e+00],\n",
      "        [ 3.2401e-01,  9.3278e-04],\n",
      "        [-2.3198e-01, -5.0639e-01],\n",
      "        [ 5.2193e-01, -3.4908e-01],\n",
      "        [ 8.0318e-01,  5.2646e-01],\n",
      "        [ 1.0614e+00,  8.3655e-01],\n",
      "        [ 1.3492e+00, -1.5456e-02],\n",
      "        [ 1.7076e-01, -5.5522e-01],\n",
      "        [ 6.1654e-01, -8.8370e-01],\n",
      "        [ 1.3629e+00, -7.0252e-01],\n",
      "        [ 2.1664e-01,  1.4138e-01],\n",
      "        [-1.8419e-01, -4.7230e-01],\n",
      "        [ 8.6686e-02,  8.6288e-03],\n",
      "        [ 1.2445e+00,  1.8123e+00],\n",
      "        [ 1.2243e+00,  1.6730e+00],\n",
      "        [-2.8163e-01, -5.4122e-01],\n",
      "        [-2.9265e-01, -6.4528e-01],\n",
      "        [ 1.0769e+00,  5.1905e-01],\n",
      "        [ 8.6319e-01, -5.2875e-02],\n",
      "        [ 1.1064e+00,  2.5398e-01],\n",
      "        [-2.5964e-01, -7.8349e-01],\n",
      "        [ 6.9294e-01, -4.0282e-01],\n",
      "        [ 4.6795e-01, -7.7420e-01],\n",
      "        [ 6.0019e-01,  7.6348e-01],\n",
      "        [-1.5772e-01, -6.8867e-01],\n",
      "        [ 1.1163e+00, -2.7841e-02],\n",
      "        [ 1.4791e-01,  8.0661e-02],\n",
      "        [ 1.6232e-01,  4.5067e-02],\n",
      "        [-4.4765e-01, -1.1991e+00],\n",
      "        [ 4.8681e-01, -6.5200e-01],\n",
      "        [-1.5995e-01, -4.0156e-01],\n",
      "        [ 3.7718e-02, -1.1478e+00],\n",
      "        [ 3.0164e-02, -4.4605e-01],\n",
      "        [ 1.6675e+00, -8.5894e-01],\n",
      "        [ 1.5564e-01, -5.5620e-01],\n",
      "        [-2.7373e-01, -9.3481e-01],\n",
      "        [ 5.4014e-01, -4.9840e-01],\n",
      "        [-1.4469e-01, -3.7674e-01],\n",
      "        [-1.2408e-01, -4.4895e-01],\n",
      "        [ 2.5172e-01,  1.2338e-01],\n",
      "        [-4.7647e-01, -1.1792e+00],\n",
      "        [-4.4709e-01, -9.8601e-01],\n",
      "        [ 1.3784e+00, -7.6669e-01],\n",
      "        [ 1.7518e+00, -9.6395e-01],\n",
      "        [ 8.7198e-01,  1.7031e-01],\n",
      "        [ 8.3138e-01,  1.0869e+00],\n",
      "        [ 1.0274e+00,  7.3511e-01],\n",
      "        [-7.6759e-02, -3.1141e-01],\n",
      "        [ 3.0537e-01,  5.5588e-02],\n",
      "        [ 7.9313e-01,  1.1060e+00],\n",
      "        [ 4.9828e-01, -9.6132e-01],\n",
      "        [ 1.5821e+00, -3.0770e-03],\n",
      "        [ 2.6185e-01, -7.7665e-01],\n",
      "        [ 2.7332e-01, -2.7701e-01],\n",
      "        [ 5.2034e-01, -4.9750e-01],\n",
      "        [ 1.5430e+00,  8.2179e-01],\n",
      "        [ 2.6985e-01, -6.9125e-01],\n",
      "        [ 3.2687e-01, -1.3074e-01],\n",
      "        [ 1.7991e-01, -2.4159e-01],\n",
      "        [ 2.2772e-01, -3.9024e-01],\n",
      "        [ 2.8128e-01,  9.5859e-02],\n",
      "        [ 6.8115e-01, -7.5478e-01],\n",
      "        [ 1.0208e+00,  1.3522e+00],\n",
      "        [-4.6673e-02, -7.8995e-01],\n",
      "        [ 1.2516e+00,  9.4376e-01],\n",
      "        [ 1.1678e-01,  4.3989e-02],\n",
      "        [ 1.0735e+00,  1.4154e+00],\n",
      "        [ 1.3099e+00,  6.7042e-01],\n",
      "        [-2.1476e-02, -6.5572e-01],\n",
      "        [ 1.3590e+00,  1.4288e+00],\n",
      "        [ 3.1275e-02, -7.5917e-01],\n",
      "        [ 1.8479e-01, -4.2720e-01],\n",
      "        [-9.0083e-02, -3.1806e-01],\n",
      "        [ 4.2151e-01, -5.2731e-01],\n",
      "        [ 9.8397e-01,  1.1021e-01],\n",
      "        [ 3.2465e-01,  3.3648e-01],\n",
      "        [-1.3935e-01, -3.5975e-01],\n",
      "        [ 1.4075e+00, -9.1297e-01],\n",
      "        [ 1.1523e+00,  1.1709e+00],\n",
      "        [ 5.1318e-01,  3.8525e-01],\n",
      "        [ 4.2515e-01,  1.6599e-01],\n",
      "        [ 4.5269e-01,  4.4055e-01],\n",
      "        [ 3.5092e-01, -2.9534e-01],\n",
      "        [ 6.9524e-01,  3.2703e-01],\n",
      "        [ 7.3889e-01,  6.5503e-01],\n",
      "        [ 8.3571e-01,  1.0468e+00],\n",
      "        [-4.4816e-03, -9.6887e-01],\n",
      "        [-7.4228e-02, -5.5228e-01],\n",
      "        [ 4.1375e-02, -2.1265e-01],\n",
      "        [-2.8781e-01, -1.0861e+00],\n",
      "        [ 1.1333e+00, -7.1091e-01],\n",
      "        [ 8.1888e-01, -2.5622e-01],\n",
      "        [-4.5585e-01, -1.3661e+00],\n",
      "        [ 3.1936e-01, -6.6471e-01],\n",
      "        [-1.6072e-01, -4.0046e-01],\n",
      "        [ 8.2410e-01, -5.8439e-01]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (155) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m optimiser\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     74\u001b[0m \u001b[39m# Calculate metrics\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m train_acc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39;49margmax(y_pred, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m==\u001b[39;49m y_train) \u001b[39m/\u001b[39m y_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     76\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     77\u001b[0m     y_pred_test \u001b[39m=\u001b[39m model(x_test)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (155) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('datasets/spiralsdataset.csv', header=None, names=['x1', 'x2', 'y'])\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data[['x1', 'x2']].to_numpy()\n",
    "y = data['y'].to_numpy()\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y = np.eye(2)[y]\n",
    "\n",
    "# Split the dataset into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the training and test data to PyTorch tensors\n",
    "x_train = torch.from_numpy(X_train).type(torch.float32)\n",
    "x_test = torch.from_numpy(X_test).type(torch.float32)\n",
    "y_train = torch.from_numpy(y_train).type(torch.float32)\n",
    "y_test = torch.from_numpy(y_test).type(torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "#Create Model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size, bias=True)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.ReLU()(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Set the hyperparameters\n",
    "input_size = 2\n",
    "hidden_size = 20\n",
    "output_size = 2\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "\n",
    "model = Model(input_size,hidden_size,output_size)\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(500):\n",
    "    # Zero gradients\n",
    "    optimiser.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "    print(y_pred)\n",
    "    # Calculate loss\n",
    "    loss = loss_fn(y_pred, y_train)   \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update weights\n",
    "    optimiser.step()\n",
    "    # Calculate metrics\n",
    "    train_acc = torch.sum(torch.argmax(y_pred, dim=1) == y_train) / y_train.shape[0]\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(x_test)\n",
    "        test_loss = loss_fn(y_pred_test, y_test)\n",
    "        test_acc = torch.sum(torch.argmax(y_pred_test, dim=1) == y_test) / y_test.shape[0]\n",
    "    # Log metrics\n",
    "    train_losses.append(loss.item())\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_losses.append(test_loss.item())\n",
    "    test_accuracies.append(test_acc)\n",
    "    if epoch % 10 == 0:\n",
    "        # Print to console\n",
    "        print(\"Epoch {}:\\tTrain loss={:.4f}  \\tTrain acc={:.2f}  \\tTest loss={:.4f}  \\tTest acc={:.2f}\".format(\n",
    "            epoch, loss.item(), train_acc*100, test_loss.item(), test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.5183\n",
      "Epoch [200/1000], Loss: 0.3875\n",
      "Epoch [300/1000], Loss: 0.3132\n",
      "Epoch [400/1000], Loss: 0.1337\n",
      "Epoch [500/1000], Loss: 0.1062\n",
      "Epoch [600/1000], Loss: 0.0482\n",
      "Epoch [700/1000], Loss: 0.0360\n",
      "Epoch [800/1000], Loss: 0.0223\n",
      "Epoch [900/1000], Loss: 0.0174\n",
      "Epoch [1000/1000], Loss: 0.0150\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the dataset\n",
    "data = pd.read_csv('datasets/spiralsdataset.csv', header=None, names=['x1', 'x2', 'y'])\n",
    "# Split the dataset into features and labels\n",
    "X = data[['x1', 'x2']].to_numpy()\n",
    "y = data['y'].to_numpy()\n",
    "# Convert the labels to one-hot encoding\n",
    "y = np.eye(2)[y]\n",
    "# Convert the features and labels to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)\n",
    "# Define the FFNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc3(x)\n",
    "        x = nn.Softmax(dim=1)(x)\n",
    "        return x\n",
    "# Set the hyperparameters\n",
    "input_size = 2\n",
    "hidden_size = 16\n",
    "output_size = 2\n",
    "learning_rate = 0.03\n",
    "num_epochs = 1000\n",
    "# Create the FFNN\n",
    "net = Net(input_size, hidden_size, output_size)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# Train the FFNN\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = net(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss_list.append(loss.item())\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "# Plot the loss\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "# Evaluate the FFNN\n",
    "# with torch.no_grad():\n",
    "#     outputs = net(X)\n",
    "#     predicted = torch.argmax(outputs, dim=1)\n",
    "# Plot the dataset with the predicted classes\n",
    "x1_min, x1_max = X[:, 0].min()-0.1, X[:, 0].max()+0.1\n",
    "x2_min, x2_max = X[:, 1].min()-0.1, X[:, 1].max()+0.1\n",
    "xx, yy = torch.meshgrid(torch.linspace(x1_min, x1_max, 100),\n",
    "                         torch.linspace(x2_min, x2_max, 100))\n",
    "X_grid = torch.cat((xx.reshape(-1,1), yy.reshape(-1,1)), dim=1)\n",
    "# Get the predicted class labels for the grid points\n",
    "with torch.no_grad():\n",
    "    grid_outputs = net(X_grid)\n",
    "    grid_predicted = torch.argmax(grid_outputs, dim=1)\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, grid_predicted.reshape(xx.shape), cmap='coolwarm', alpha=0.5)\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=y.argmax(axis=1), cmap='coolwarm')\n",
    "plt.title('Test Data with Decision Boundary')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
