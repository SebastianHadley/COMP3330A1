import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import matplotlib.pyplot as plt

# Load the two-spiral dataset
data = pd.read_csv('datasets/spiralsdataset.csv', header=None, names=['x1','x2','y'])

# Split the data into features and labels
X = data[['x1', 'x2']].to_numpy()
y = data[['y']].to_numpy().flatten()

# Plot the dataset
plt.scatter(X[:,0], X[:,1], c=y)
plt.show()

# Define the neural network architecture
class Net(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        self.activation = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.activation(x)
        x = self.fc2(x)
        return x

# Set the hyperparameters
input_size = 2
hidden_size = 16
output_size = 2
learning_rate = 0.01
num_epochs = 1000

# Create the neural network
net = Net(input_size, hidden_size, output_size)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)

# Train the neural network
for epoch in range(num_epochs):
    # Convert inputs and labels to PyTorch tensors
    inputs = torch.from_numpy(X).float()
    labels = torch.from_numpy(y).long()

    # Zero the gradients
    optimizer.zero_grad()

    # Forward pass
    outputs = net(inputs)

    # Compute the loss
    loss = criterion(outputs, labels)

    # Backward pass
    loss.backward()

    # Update the weights
    optimizer.step()

    # Print the loss every 100 epochs
    if (epoch+1) % 100 == 0:
        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))

# Get the predicted labels for the inputs
_, predicted = torch.max(net(inputs).data, 1)
predicted = predicted.numpy()

# Plot the predicted labels
plt.scatter(X[:,0], X[:,1], c=predicted)
plt.show()
